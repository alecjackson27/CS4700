Just writing down notes that might be helpful for presentation in here

In Haskell, like most purely functional languages, data is immutable. Here is an example 
from the Haskell interpreter that seems to contradict the "data is immutable" aspect of 
Haskell, but actually doesn't:

Prelude> let a = 3
Prelude> a
3
Prelude> a = 5
Prelude> a
5

This seems like we have changed data, but we haven't. What has actually happened is a 
new definition has been created which is also named a (and the original instance of a
has been hidden from the scope of any code written after this). The difference can be seen
with this example from the Haskell interpreter:

Prelude> let b = 99
Prelude> f x = b * x
Prelude> b = 100
Prelude> b
100
Prelude> f 2
198

The reference to b in the function f still refers to the original instance of b, which 
cannot be changed. Here's another example of immutable data with a list:

Prelude> lst = [1, 2, 3]
Prelude> lst !! 1 = 7
Prelude> lst
[1,2,3]

Even though we set the value at index 1 of lst to equal 7, it still equals 2

On Being Purely Functional:
Haskell is a purely functional language and functions do not have side effects, which is the reason for its inherent parallelism (along with some other benefits). However, side effects re necessary for some basic progrmming tasks such as input output. To compensate for this, Haskell separates functions which are pure and functions which perform tasks such as input/output, allowing computations to be completely functionally pure, after which the non-pure functions can use the data returned by the pure functions for things like input/output and writingto/reading from files. One thing to note is that Lisp, while generally considered a functional language, is not purely functional like Haskell. It a language which both supports and encourages a functional styyle, but is actually possible to program in an imperative style in Lisp, side effects and all.

One thing that is interesting about parallelism in Haskell is that the you simply need to identify
which expressions can be evaluated in parallel and Haskell while compiling will make a determination
as to whether the cost of evaluating an expresison in parallel is worth the parallel overhead.

Haskell uses "lazy evaluaton" which means expressions aren't evaluated until they
are needed. This allows Haskell to avoid wasting resources evaluating functions
and other expressions which are never used and also allows for infinite lists such
as [1..], as each element of the list is only evaluated which it is needed.